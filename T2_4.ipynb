{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "## 4. Entendimiento de imágenes de personas\n",
    "\n",
    "El problema de inferir ciertas características de una persona a través de una foto de ella puede resultar bastante difícil incluso para nosotros, como por ejemplo de qué país es, la emoción que expresa, la edad que tiene, o el género. La automatización de este proceso para que máquinas logren identificar ciertas características de una persona puede ser algo crucial para el futuro desarrollo de Inteligencia Artificial.\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/6B072GE.jpg\" width=\"60%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "En esta actividad trabajaremos con unos datos (imágenes) con la tarea de predecir la **edad** (*target value*) de la persona en la imagen. Los datos con corresponden a 3640 imágenes de Flickr de rostros de personas, pero para simplificar el manejo y cómputo, se trabajará con representaciones de características extraídas (descriptores). Para ésto necesitará descargar los datos del siguiente __[link](http://chenlab.ece.cornell.edu/people/Andy/ImagesOfGroups.html)__ en el extracto de *ageGenderClassification* o a través de la consola Unix.\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/ageGenderClassification.zip\n",
    "```\n",
    "\n",
    "Se trabajará con archivos *.mat* que pueden ser cargados de la siguiente manera:\n",
    "```python\n",
    "import scipy.io as sio\n",
    "sio.loadmat(\"file.mat\")\n",
    "```\n",
    "\n",
    "Para descripción sobre las columnas y metadatos del archivo descargado favor dirigirse al archivo readme a través del siguiente __[link](http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt)__ o a través de la consola Unix:\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt\n",
    "```\n",
    "En el apartado \"*MATLAB DATA*\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a) Cargue los datos dos dataset de entrenamiento y de pruebas ¿Cuántos datos hay en cada conjunto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "mat_train = sio.loadmat(\"./eventrain.mat\")\n",
    "mat_test = sio.loadmat(\"./eventest.mat\")\n",
    "data_train= mat_train[\"trcoll\"][0][0]\n",
    "data_test= mat_test[\"tecoll\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se tienen  11  columnas y  3500  filas  para el conjunto de entrenamiento\n",
      "se tienen  11  columnas y  1050  filas  para el conjunto de prueba\n"
     ]
    }
   ],
   "source": [
    "print(\"se tienen \", len(data_train),\" columnas y \", len(data_train[1]), \" filas  para el conjunto de entrenamiento\")\n",
    "print(\"se tienen \", len(data_test),\" columnas y \", len(data_test[1]), \" filas  para el conjunto de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta interpretación surge del hecho de que la información se almacena en un arreglo de arreglos, por tanto se interpreta cada arreglo como una columna distinta de otra, con lo que se ilustrará con un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51]\n",
      " [28]\n",
      " [28]\n",
      " ...\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "print(data_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note tambien que cada dato por si solo también es un arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN, Created on: Tue Nov 18 15:31:22 2008',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'tecoll': array([[(array([[87.        , 35.        ,  1.        , ...,  1.09343236,\n",
       "          1.        ,  5.        ],\n",
       "        [32.        , 60.        ,  1.        , ...,  0.97426295,\n",
       "          1.        ,  5.        ],\n",
       "        [41.        , 65.        ,  2.        , ...,  0.94143991,\n",
       "          1.        ,  5.        ],\n",
       "        ...,\n",
       "        [34.        , 59.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  6.        ],\n",
       "        [65.        , 58.        ,  1.        , ...,  1.11063618,\n",
       "          2.        ,  1.        ],\n",
       "        [33.        , 11.        ,  1.        , ...,  1.        ,\n",
       "          2.        ,  2.        ]]), array([[28],\n",
       "        [28],\n",
       "        [28],\n",
       "        ...,\n",
       "        [10],\n",
       "        [10],\n",
       "        [10]], dtype=uint8), array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=uint8), array([[-0.07947878, -0.02329917,  0.03531325, ..., -0.00126247,\n",
       "          0.01194425,  0.04064064],\n",
       "        [-0.08916005, -0.04968512, -0.00280512, ..., -0.03094351,\n",
       "         -0.02624821,  0.03677384],\n",
       "        [-0.07610574, -0.06886108, -0.06147822, ...,  0.02330778,\n",
       "          0.04573343,  0.03820887],\n",
       "        ...,\n",
       "        [ 0.03590869, -0.06111767,  0.00526192, ...,  0.00134686,\n",
       "         -0.00165603,  0.00353202],\n",
       "        [ 0.00941825,  0.03351382, -0.02503798, ...,  0.05614099,\n",
       "          0.03449292, -0.03372488],\n",
       "        [-0.12553122, -0.04003964,  0.03402196, ..., -0.00921742,\n",
       "         -0.01880107,  0.03083811]]), array([[  16.453856 ,   34.83934  ,   48.7035   , ..., -198.66533  ,\n",
       "          109.027985 ,   78.18502  ],\n",
       "        [  53.82186  ,   93.61051  ,   65.62783  , ...,  657.3836   ,\n",
       "          820.10693  , -132.57458  ],\n",
       "        [   6.8143125,  -20.586594 ,  -50.35877  , ..., -409.62454  ,\n",
       "         -196.4159   ,  111.17357  ],\n",
       "        ...,\n",
       "        [ -34.0235   ,  -75.17138  ,  -87.20992  , ..., -212.65627  ,\n",
       "         -301.569    , -366.88312  ],\n",
       "        [  17.623787 ,    2.0862489,  -15.78859  , ...,   20.659277 ,\n",
       "          155.44498  ,  404.44925  ],\n",
       "        [ -29.624369 ,  -83.67899  ,  -97.403336 , ...,  416.36523  ,\n",
       "          415.95398  ,  -69.081314 ]], dtype=float32), array([[ 23,  25,  26, ..., 128, 124, 119],\n",
       "        [119, 107,  88, ...,  60,  53,  56],\n",
       "        [ 82,  70,  56, ..., 138, 138, 139],\n",
       "        ...,\n",
       "        [ 26,  30,  28, ...,  99,  86,  88],\n",
       "        [128, 126, 125, ..., 129,  96,  91],\n",
       "        [ 24,  24,  22, ...,  45,  31,  17]], dtype=uint8), array([[0.46534653],\n",
       "        [0.34653465],\n",
       "        [0.46534653],\n",
       "        ...,\n",
       "        [0.26732673],\n",
       "        [0.57425743],\n",
       "        [0.31683168]]), array([[ 3.62191781],\n",
       "        [29.77808219],\n",
       "        [32.3890411 ],\n",
       "        ...,\n",
       "        [29.61917808],\n",
       "        [32.57260274],\n",
       "        [20.59452055]]), array([[array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\FamilyPortraitRel1\\\\2225775560_c1eb8fa51a_2006_23234180@N02.jpg'],\n",
       "       dtype='<U101'),\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\FamilyPortraitRel1\\\\2225775560_c1eb8fa51a_2006_23234180@N02.jpg'],\n",
       "       dtype='<U101'),\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\FamilyPortraitRel1\\\\2225775560_c1eb8fa51a_2006_23234180@N02.jpg'],\n",
       "       dtype='<U101'),\n",
       "         ...,\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\AGroupPortraitRel1\\\\1560465722_7365be3e77_2015_10864931@N08.jpg'],\n",
       "       dtype='<U101'),\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\AGroupPortraitRel1\\\\1812722430_8b9523b88b_2209_60141658@N00.jpg'],\n",
       "       dtype='<U101'),\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\AGroupPortraitRel1\\\\2044988873_6aad112b43_2031_98359355@N00.jpg'],\n",
       "       dtype='<U101')]], dtype=object), array([[868.      , 260.      , 890.      , ..., 879.      , 262.      ,\n",
       "          22.36068 ],\n",
       "        [304.      , 454.      , 326.      , ..., 315.      , 452.      ,\n",
       "          22.36068 ],\n",
       "        [396.      , 492.      , 418.      , ..., 407.      , 491.      ,\n",
       "          22.090721],\n",
       "        ...,\n",
       "        [147.      , 224.      , 188.      , ..., 167.5     , 219.      ,\n",
       "          42.201897],\n",
       "        [644.      , 434.      , 668.      , ..., 656.      , 435.      ,\n",
       "          24.083189],\n",
       "        [236.      , 108.      , 252.      , ..., 244.      , 109.      ,\n",
       "          16.124516]], dtype=float32), array([[  11, 1458],\n",
       "        [  11, 1459],\n",
       "        [  11, 1460],\n",
       "        ...,\n",
       "        [   4,  836],\n",
       "        [   4, 1080],\n",
       "        [   4, 1340]], dtype=uint16))]],\n",
       "       dtype=[('genFeat', 'O'), ('ageClass', 'O'), ('genClass', 'O'), ('ffcoefs', 'O'), ('faceGist', 'O'), ('faceimg', 'O'), ('genderGuessNN', 'O'), ('ageGuess1', 'O'), ('name', 'O'), ('facePosSize', 'O'), ('origin', 'O')])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- genFeat: contiene el \"nombre\" dela imagen que contiene al rostro\n",
    "- ageClass: contiene la edad del rostro\n",
    "- genClass: contiene genero\n",
    "- ffcoef: es una proyeccion del rostro a un espacio de fisherman. Util para medicion de similitud facial. \n",
    "- faceGist: Sin descripción\n",
    "- faceimg: sin descripción\n",
    "- genderGuessNN: sin descripcion\n",
    "- ageGuess: sin descripcion\n",
    "- name: nombre de la imagen\n",
    "- facePosSize: posición del rostro\n",
    "- Origin: sin descripcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Elija cuál representación utilizará para trabajar los datos y entregárselos como *input* al modelo de aprendizaje a utilizar, recuerde que puede utilizar una combinación de éstos si lo desea. Además extraiga las salidas/*output* del problema, en este caso, como ya se comentó, la edad. Describa los datos utilizados y la cantidad de datos por rango de edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(lista):\n",
    "    lst=[]\n",
    "    for i in range(len(lista)):\n",
    "        lst.append(lista[i][0])\n",
    "    lista = lst\n",
    "    return lista;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar se generarán las tablas con las que se trabajarán. Se considerarán las primeras 4 variables, debido a que son las que poseen información más clara en la documentación de la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "##############################################\n",
    "#                 Training Data              #\n",
    "############################################## \n",
    "df_train = pd.DataFrame()#Dataframe de entrenamiento\n",
    "genFeat = extractor(data_train[0])#it can be used as representation: contextual features\n",
    "df_train['genFeat'] = pd.Series(genFeat)\n",
    "ageClass = extractor(data_train[1])#target\n",
    "df_train['ageClass'] = pd.Series(ageClass)\n",
    "genClass = extractor(data_train[2])\n",
    "df_train['genClass'] = pd.Series(genClass)\n",
    "ffcoef = extractor(data_train[3])#it can be used as representation: fisherface space\n",
    "df_train['ffcoef'] = pd.Series(ffcoef)\n",
    "faceGist = extractor(data_train[4])#it can be used as representation\n",
    "df_train['faceGist'] = pd.Series(faceGist)\n",
    "faceimg = extractor(data_train[5])\n",
    "genderGuessNN = extractor(data_train[6])\n",
    "ageGuess = extractor(data_train[7])\n",
    "name = extractor(data_train[8])\n",
    "facePosSize = extractor(data_train[9])\n",
    "Origin = extractor(data_train[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genFeat</th>\n",
       "      <th>ageClass</th>\n",
       "      <th>genClass</th>\n",
       "      <th>ffcoef</th>\n",
       "      <th>faceGist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>0.043865</td>\n",
       "      <td>5.919031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0.016909</td>\n",
       "      <td>5.457365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genFeat  ageClass  genClass    ffcoef  faceGist\n",
       "0     42.0        51         2  0.043865  5.919031\n",
       "1     60.0        28         2  0.016909  5.457365"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "#                  Test  Data                #\n",
    "############################################## \n",
    "df_test = pd.DataFrame()#Dataframe de entrenamiento\n",
    "genFeat = extractor(data_test[0])#it can be used as representation: contextual features\n",
    "df_test['genFeat'] = pd.Series(genFeat)\n",
    "ageClass = extractor(data_test[1])#target\n",
    "df_test['ageClass'] = pd.Series(ageClass)\n",
    "genClass = extractor(data_test[2])\n",
    "df_test['genClass'] = pd.Series(genClass)\n",
    "ffcoef = extractor(data_test[3])#it can be used as representation: fisherface space\n",
    "df_test['ffcoef'] = pd.Series(ffcoef)\n",
    "faceGist = extractor(data_test[4])#it can be used as representation\n",
    "df_test['faceGist'] = pd.Series(faceGist)\n",
    "faceimg = extractor(data_test[5])\n",
    "genderGuessNN = extractor(data_test[6])\n",
    "ageGuess = extractor(data_test[7])\n",
    "name = extractor(data_test[8])\n",
    "facePosSize = extractor(data_test[9])\n",
    "Origin = extractor(data_test[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genFeat</th>\n",
       "      <th>ageClass</th>\n",
       "      <th>genClass</th>\n",
       "      <th>ffcoef</th>\n",
       "      <th>faceGist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.079479</td>\n",
       "      <td>16.453856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.089160</td>\n",
       "      <td>53.821861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.076106</td>\n",
       "      <td>6.814312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genFeat  ageClass  genClass    ffcoef   faceGist\n",
       "0     87.0        28         1 -0.079479  16.453856\n",
       "1     32.0        28         1 -0.089160  53.821861\n",
       "2     41.0        28         1 -0.076106   6.814312"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora generaremos el conjunto de entrenamiento y de pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train =df_train[\"ageClass\"].values\n",
    "df_train.drop(\"ageClass\",axis=1,inplace=True)\n",
    "X_train = df_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3500 entries, 0 to 3499\n",
      "Data columns (total 4 columns):\n",
      "genFeat     3500 non-null float64\n",
      "genClass    3500 non-null int64\n",
      "ffcoef      3500 non-null float64\n",
      "faceGist    3500 non-null float64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 109.5 KB\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.countplot(x=Y_train)\n",
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.xticks(rotation=70)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test =df_test[\"ageClass\"].values\n",
    "df_test.drop(\"ageClass\",axis=1,inplace=True)\n",
    "X_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6]), <a list of 7 Text xticklabel objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.countplot(x=Y_test)\n",
    "plt.rcParams['xtick.labelsize'] = 13\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Defina y entrene modelos de aprendizaje para la inferencia de la edad de la persona a través de la representación escogida, *se espera que experimente con distintas configuraciones, modelos e hiper-parámetros* . Intente llegar a un *MSE* menor a 100 sobre la edad de las personas en el conjunto de pruebas. Recuerde que **NO** puede seleccionar modelos a través del conjunto de pruebas. Visualice sus resultados si estima conveniente.\n",
    "\n",
    "\n",
    "*Nota: Puede notar que la cantidad de edades presentes en el problema son pocas (1,  5, 10, 16, 28, 51 o 75 años), por lo que puede tratar al problema así como de regresión o clasificación (considerando cada edad como una clase)*\n",
    "\n",
    "\n",
    "#### Ayuda:\n",
    "\n",
    "> Para problemas de clasificación de múltiples clases, la red neuronal de *keras* necesita una represnetacion *one hot vector* similar a lo comentado en la sección 2, por lo que será necesario transformar/codificar las edades a etiquetas categóricas, donde cada columna del vector representará una categoría. Por ejemplo, si existen tres categorías (perro, gato, ratón), la categoría perro puede ser codificada como [1,0,0], y la categoría ratón puede ser codificada como [0,0,1]. Para ésto la librería *keras* nos ayuda:\n",
    "\n",
    "<div class=\"alert alert-warning\"> Recuerde que si trabaja el problema como clasificación deberá invertir la transformación de codificación de las edades a clases, para así poder evaluar el MSE </div>\n",
    "\n",
    "```python\n",
    "import keras\n",
    "y_onehot = keras.utils.to_categorical(y_train,num_classes=edades_distintas)\n",
    "```\n",
    "\n",
    "*Recuerde que:* Si encuentra que la métrica evaluadora le perjudica puede acudir a otras para entender el qué está pasando con su modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kzep\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#Y_train= keras.utils.to_categorical(Y_train,num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642.8105815911581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = DecisionTreeRegressor(criterion='mse', splitter='random', max_depth=5)\n",
    "model.fit(X_train,Y_train)\n",
    "print(mean_squared_error(model.predict(X_test),Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087.624761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "model.fit(X_train,Y_train)\n",
    "print(mean_squared_error(model.predict(X_test),Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748.4644561101778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "model = SVR(gamma=6, C=0.7, epsilon=0.4)\n",
    "model.fit(X_train,Y_train)\n",
    "print(mean_squared_error(model.predict(X_test),Y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
