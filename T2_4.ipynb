{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "## 4. Entendimiento de imágenes de personas\n",
    "\n",
    "El problema de inferir ciertas características de una persona a través de una foto de ella puede resultar bastante difícil incluso para nosotros, como por ejemplo de qué país es, la emoción que expresa, la edad que tiene, o el género. La automatización de este proceso para que máquinas logren identificar ciertas características de una persona puede ser algo crucial para el futuro desarrollo de Inteligencia Artificial.\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/6B072GE.jpg\" width=\"60%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "En esta actividad trabajaremos con unos datos (imágenes) con la tarea de predecir la **edad** (*target value*) de la persona en la imagen. Los datos con corresponden a 3640 imágenes de Flickr de rostros de personas, pero para simplificar el manejo y cómputo, se trabajará con representaciones de características extraídas (descriptores). Para ésto necesitará descargar los datos del siguiente __[link](http://chenlab.ece.cornell.edu/people/Andy/ImagesOfGroups.html)__ en el extracto de *ageGenderClassification* o a través de la consola Unix.\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/ageGenderClassification.zip\n",
    "```\n",
    "\n",
    "Se trabajará con archivos *.mat* que pueden ser cargados de la siguiente manera:\n",
    "```python\n",
    "import scipy.io as sio\n",
    "sio.loadmat(\"file.mat\")\n",
    "```\n",
    "\n",
    "Para descripción sobre las columnas y metadatos del archivo descargado favor dirigirse al archivo readme a través del siguiente __[link](http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt)__ o a través de la consola Unix:\n",
    "```\n",
    "wget http://chenlab.ece.cornell.edu/projects/ImagesOfGroups/README.txt\n",
    "```\n",
    "En el apartado \"*MATLAB DATA*\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a) Cargue los datos dos dataset de entrenamiento y de pruebas ¿Cuántos datos hay en cada conjunto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "mat_train = sio.loadmat(\"./eventrain.mat\")\n",
    "mat_test = sio.loadmat(\"./eventest.mat\")\n",
    "data_train= mat_train[\"trcoll\"][0][0]\n",
    "data_test= mat_test[\"tecoll\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se tienen  11  columnas y  3500  filas \n"
     ]
    }
   ],
   "source": [
    "print(\"se tienen \", len(data_train),\" columnas y \", len(data_train[1]), \" filas  para el conjunto de entrenamiento\")\n",
    "print(\"se tienen \", len(data_test),\" columnas y \", len(data_test[1]), \" filas  para el conjunto de prueba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta interpretación surge del hecho de que la información se almacena en un arreglo de arreglos, por tanto se interpreta cada arreglo como una columna distinta de otra, con lo que se ilustrará con un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51]\n",
      " [28]\n",
      " [28]\n",
      " ...\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "print(data_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note tambien que cada dato por si solo también es un arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN, Created on: Tue Nov 18 15:31:22 2008',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'tecoll': array([[(array([[87.        , 35.        ,  1.        , ...,  1.09343236,\n",
       "          1.        ,  5.        ],\n",
       "        [32.        , 60.        ,  1.        , ...,  0.97426295,\n",
       "          1.        ,  5.        ],\n",
       "        [41.        , 65.        ,  2.        , ...,  0.94143991,\n",
       "          1.        ,  5.        ],\n",
       "        ...,\n",
       "        [34.        , 59.        ,  1.        , ...,  1.        ,\n",
       "          1.        ,  6.        ],\n",
       "        [65.        , 58.        ,  1.        , ...,  1.11063618,\n",
       "          2.        ,  1.        ],\n",
       "        [33.        , 11.        ,  1.        , ...,  1.        ,\n",
       "          2.        ,  2.        ]]), array([[28],\n",
       "        [28],\n",
       "        [28],\n",
       "        ...,\n",
       "        [10],\n",
       "        [10],\n",
       "        [10]], dtype=uint8), array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=uint8), array([[-0.07947878, -0.02329917,  0.03531325, ..., -0.00126247,\n",
       "          0.01194425,  0.04064064],\n",
       "        [-0.08916005, -0.04968512, -0.00280512, ..., -0.03094351,\n",
       "         -0.02624821,  0.03677384],\n",
       "        [-0.07610574, -0.06886108, -0.06147822, ...,  0.02330778,\n",
       "          0.04573343,  0.03820887],\n",
       "        ...,\n",
       "        [ 0.03590869, -0.06111767,  0.00526192, ...,  0.00134686,\n",
       "         -0.00165603,  0.00353202],\n",
       "        [ 0.00941825,  0.03351382, -0.02503798, ...,  0.05614099,\n",
       "          0.03449292, -0.03372488],\n",
       "        [-0.12553122, -0.04003964,  0.03402196, ..., -0.00921742,\n",
       "         -0.01880107,  0.03083811]]), array([[  16.453856 ,   34.83934  ,   48.7035   , ..., -198.66533  ,\n",
       "          109.027985 ,   78.18502  ],\n",
       "        [  53.82186  ,   93.61051  ,   65.62783  , ...,  657.3836   ,\n",
       "          820.10693  , -132.57458  ],\n",
       "        [   6.8143125,  -20.586594 ,  -50.35877  , ..., -409.62454  ,\n",
       "         -196.4159   ,  111.17357  ],\n",
       "        ...,\n",
       "        [ -34.0235   ,  -75.17138  ,  -87.20992  , ..., -212.65627  ,\n",
       "         -301.569    , -366.88312  ],\n",
       "        [  17.623787 ,    2.0862489,  -15.78859  , ...,   20.659277 ,\n",
       "          155.44498  ,  404.44925  ],\n",
       "        [ -29.624369 ,  -83.67899  ,  -97.403336 , ...,  416.36523  ,\n",
       "          415.95398  ,  -69.081314 ]], dtype=float32), array([[ 23,  25,  26, ..., 128, 124, 119],\n",
       "        [119, 107,  88, ...,  60,  53,  56],\n",
       "        [ 82,  70,  56, ..., 138, 138, 139],\n",
       "        ...,\n",
       "        [ 26,  30,  28, ...,  99,  86,  88],\n",
       "        [128, 126, 125, ..., 129,  96,  91],\n",
       "        [ 24,  24,  22, ...,  45,  31,  17]], dtype=uint8), array([[0.46534653],\n",
       "        [0.34653465],\n",
       "        [0.46534653],\n",
       "        ...,\n",
       "        [0.26732673],\n",
       "        [0.57425743],\n",
       "        [0.31683168]]), array([[ 3.62191781],\n",
       "        [29.77808219],\n",
       "        [32.3890411 ],\n",
       "        ...,\n",
       "        [29.61917808],\n",
       "        [32.57260274],\n",
       "        [20.59452055]]), array([[array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\FamilyPortraitRel1\\\\2225775560_c1eb8fa51a_2006_23234180@N02.jpg'],\n",
       "       dtype='<U101'),\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\FamilyPortraitRel1\\\\2225775560_c1eb8fa51a_2006_23234180@N02.jpg'],\n",
       "       dtype='<U101'),\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\FamilyPortraitRel1\\\\2225775560_c1eb8fa51a_2006_23234180@N02.jpg'],\n",
       "       dtype='<U101'),\n",
       "         ...,\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\AGroupPortraitRel1\\\\1560465722_7365be3e77_2015_10864931@N08.jpg'],\n",
       "       dtype='<U101'),\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\AGroupPortraitRel1\\\\1812722430_8b9523b88b_2209_60141658@N00.jpg'],\n",
       "       dtype='<U101'),\n",
       "         array(['c:\\\\research\\\\flickr\\\\query_groupShots\\\\Q4\\\\AGroupPortraitRel1\\\\2044988873_6aad112b43_2031_98359355@N00.jpg'],\n",
       "       dtype='<U101')]], dtype=object), array([[868.      , 260.      , 890.      , ..., 879.      , 262.      ,\n",
       "          22.36068 ],\n",
       "        [304.      , 454.      , 326.      , ..., 315.      , 452.      ,\n",
       "          22.36068 ],\n",
       "        [396.      , 492.      , 418.      , ..., 407.      , 491.      ,\n",
       "          22.090721],\n",
       "        ...,\n",
       "        [147.      , 224.      , 188.      , ..., 167.5     , 219.      ,\n",
       "          42.201897],\n",
       "        [644.      , 434.      , 668.      , ..., 656.      , 435.      ,\n",
       "          24.083189],\n",
       "        [236.      , 108.      , 252.      , ..., 244.      , 109.      ,\n",
       "          16.124516]], dtype=float32), array([[  11, 1458],\n",
       "        [  11, 1459],\n",
       "        [  11, 1460],\n",
       "        ...,\n",
       "        [   4,  836],\n",
       "        [   4, 1080],\n",
       "        [   4, 1340]], dtype=uint16))]],\n",
       "       dtype=[('genFeat', 'O'), ('ageClass', 'O'), ('genClass', 'O'), ('ffcoefs', 'O'), ('faceGist', 'O'), ('faceimg', 'O'), ('genderGuessNN', 'O'), ('ageGuess1', 'O'), ('name', 'O'), ('facePosSize', 'O'), ('origin', 'O')])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Elija cuál representación utilizará para trabajar los datos y entregárselos como *input* al modelo de aprendizaje a utilizar, recuerde que puede utilizar una combinación de éstos si lo desea. Además extraiga las salidas/*output* del problema, en este caso, como ya se comentó, la edad. Describa los datos utilizados y la cantidad de datos por rango de edad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_test\n",
    "genFeat = data[0]  #it can be used as representation: contextual features\n",
    "ageClass = data[1] #target\n",
    "ffcoefs = data[3]   #it can be used as representation: fisherface space\n",
    "faceGist = data[4]  #it can be used as representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28],\n",
       "       [28],\n",
       "       [28],\n",
       "       ...,\n",
       "       [10],\n",
       "       [10],\n",
       "       [10]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
